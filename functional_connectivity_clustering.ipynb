{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d040765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from nilearn import input_data\n",
    "from numpy import save\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71ec4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function\n",
    "\n",
    "def get_dot(seed_time_series, region_time_series):\n",
    "    \n",
    "    '''function that takes as input the time series of a seed and time series of a region,\n",
    "    and returns the correlation between the them\n",
    "    '''    \n",
    "    \n",
    "    flattened_seed = np.ravel(seed_time_series)\n",
    "    flattened_region = np.ravel(region_time_series)\n",
    "    \n",
    "    dot_p = np.dot(flattened_region,flattened_seed)/flattened_seed.shape[0]\n",
    "    \n",
    "    return dot_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c5b6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function\n",
    "\n",
    "def time_series(coords, func, confounds):\n",
    "    \n",
    "    ''' Function that takes as input the seed coordinates, func & confounds files of a \n",
    "    subject and returns the time series of the seed\n",
    "    '''\n",
    "    mask = input_data.NiftiSpheresMasker(\n",
    "    coords, radius=10,\n",
    "    detrend=True, standardize=True,\n",
    "    low_pass=0.1, high_pass=0.01, t_r=2,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=0)\n",
    "    \n",
    "    time_series = mask.fit_transform(func,\n",
    "                confounds=[confounds])\n",
    "    \n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "104c2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to files\n",
    "\n",
    "ADNI_dir = '/Users/natashaclarke/Documents/brainhack/ADNI_matched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6aa67526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a .txt file listing all confound files in your directory. We then loop through them and add them to a list\n",
    "\n",
    "confound_data = []\n",
    "conf_file = open((os.path.join(ADNI_dir, 'confound_files.txt')),'r')\n",
    "for line in conf_file:\n",
    "    confound_data.append(os.path.join(ADNI_dir,(line.strip())))\n",
    "conf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "944bb7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a .txt file listing all func files in your directory. We then loop through them and add them to a list\n",
    "\n",
    "func_data = []\n",
    "func_file = open((os.path.join(ADNI_dir, 'func_files.txt')),'r')\n",
    "for line in func_file:\n",
    "    func_data.append(os.path.join(ADNI_dir,(line.strip())))\n",
    "func_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52bc38ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of func_data = 20\n",
      "Length of confound_data = 20\n"
     ]
    }
   ],
   "source": [
    "# check that there are as many files as you expected (and that the lengths match!)\n",
    "\n",
    "print ('Length of func_data =', len(func_data))\n",
    "print ('Length of confound_data =', len(confound_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12154c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the lists so they are in order\n",
    "\n",
    "func_sorted = sorted(func_data)\n",
    "confound_sorted = sorted(confound_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d87e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed coordinates. Current seed = left anterior medial temporal gyrus\n",
    "\n",
    "seed_coords = [(-60, -6, 18)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5b9842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give coorrdinates of ROIs that we want to calculate connectivity with the seed\n",
    "\n",
    "L_angular = [(-46,-62,34)]\n",
    "medial_prefront = [(0,60,-8)]\n",
    "post_cing = [(-3,-49,33)]\n",
    "R_aMTG = [(60,-10,-18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43d8dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for the ROIs\n",
    "\n",
    "regions_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be9e7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ROIs to dictionary with name as the key and coordinates as the value\n",
    "\n",
    "regions_dict['L_angular'] = L_angular\n",
    "regions_dict['medial_prefront'] = medial_prefront\n",
    "regions_dict['post_cing'] = post_cing\n",
    "regions_dict['R_aMTG'] = R_aMTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cc87d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loop through the files in your sorted lists. For each, we first calculate the seed time series\n",
    "and times series of each of our ROIs. Then, calculate the correlation between\n",
    "the seed time series and each ROI time series and add them to a df'''\n",
    "\n",
    "# create an empty df with the column headers of our ROIs\n",
    "df_corr = pd.DataFrame(data=0, columns=regions_dict, index=range(0))\n",
    "\n",
    "for func, confounds in zip(func_sorted, confound_sorted):\n",
    "    subject_seed = time_series(seed_coords, func, confounds)  # calculate subject seed time-series\n",
    "\n",
    "    region_series_list = []\n",
    "    for region, coord in regions_dict.items():\n",
    "        region_series = time_series(coord, func, confounds)   # calculate time series of each ROI\n",
    "        region_series_list.append(region_series)\n",
    "        \n",
    "    correlation = []\n",
    "    for series in region_series_list:\n",
    "        dot = series_corr.get_dot(subject_seed, series)       # correlate seed and ROI time series\n",
    "        correlation.append(dot)\n",
    "    \n",
    "    correlation = pd.Series(correlation, index = df_corr.columns)\n",
    "    df_corr = df_corr.append(correlation, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45a48882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to array for clustering\n",
    "\n",
    "X = df_corr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ecc3ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X to npy file for later\n",
    "\n",
    "save('clustering_X.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b462c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the correlations df that lists the func file, and save to excel\n",
    "\n",
    "df_corr['file'] = func_sorted\n",
    "df_corr.to_excel('correlations.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9337a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate clustering models and fit to data. You can add/ change the models using the scikit learn documentation\n",
    "# for the 2 Agglomerative clustering models, either set the distance_threshold or n_clusters\n",
    "\n",
    "model1_ward = AgglomerativeClustering(linkage='ward', distance_threshold=None, n_clusters=2).fit(X)\n",
    "model2_average = AgglomerativeClustering(linkage='average', distance_threshold=None, n_clusters=2).fit(X)\n",
    "model3_KMeans = KMeans(n_clusters=2, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f61fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle models to save to disk\n",
    "\n",
    "pickle.dump(model1_ward, open('model1_ward.sav', 'wb'))\n",
    "pickle.dump(model2_average, open('model2_average.sav', 'wb'))\n",
    "pickle.dump(model3_KMeans, open('model3_KMeans.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e13fcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congratulations! You just trained three clustering models using seed-based functional connectivity!\n",
    "# Head over to the clustering_visualization notebook to explore how your clustering algorithms did"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
